Tipos de Árboles de decisión y aplicaciones
Los árboles de decisión son una herramienta poderosa que permite evaluar muchas posibilidades para tomar una decisión.
Según el algorítmo, se pueden clasificar como:
- ID3 (Iterative Dichotomiser 3): Este algoritmo es precursor del C4.5, usado en procesamiento de lenguaje natural (NLP). Utiliza la entropía como criterio de división. Encuentra óptimos locales, puede sobre ajustar los datos.
- C4.5: Es usado como clasificador. Mejora el anterior con algunas optimizaciones.
- CART (Classification And Regression Tree): Incluye dos tipos, el primero, los árboles de clasificación, cuando la salida predecida es la clase (discreta) a la que pertenecen los datos, es decir, clasifica los datos. El segundo, los árboles de regresión, cuando la salida puede ser considerada un número real, por ejemplo el precio de un producto. Ambos son similares, pero también cuentan con algunas diferencias, por ejemplo, en los criterios de división. Son muy usado en ciencias.
- CHAID (CHi-squared Automatic Interaction Detector): Se basa en la prueba de significancia ajustada, realiza divisiones multinivel para clasificación. Muy usado para predecir grupos de consumidores.
- MARS: Extiende los árboles de decisión para operar con datos numéricos con no linearidades e interacciones entre variables.
- QUEST (Quick, Unbiased, Efficient, Statistical Tree): Realiza particiones en combinaciones lineales entre variables.
- Conditional Inference Trees: Aproximación basada en estadística que usa pruebas no paramétricas para la partición, es insesgado y no requiere poda.
Algunas técnicas, llamadas ensembles, realizan la construcción de varios árboles de decisión en el proceso, algunas de ellas son:
- Bagging o Bootstrap aggregated: Construye múltiples árboles por remuestreo repetido de los datos de entrenamiento. Elimina los errores tanto como es posible. Es muy usado en matemáticas y contabilidad.
- Random Forest: Es un caso particular del anterior, corrige la sobre ajuste de los datos.
- Boosted trees: Entrena cada nuevo árbol con la información perdida de la clasificación anterior
- Rotation Forest: Cada árbol es entrenado usando Análisis de Coomponentes principales.
- Decision List: Un árbol que solo se va por una única rama, generando una única lista.


Referencias: 
- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4466856/
- https://www.geniolandia.com/13175310/tipos-de-arboles-de-decision
- https://www.linkedin.com/pulse/what-decision-trees-types-why-important-srinivas-kilambi
- https://en.wikipedia.org/wiki/Decision_tree_learning
